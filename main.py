
from fastapi import FastAPI, HTTPException, Header
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
import base64
import math
import os

# -----------------------------
# LOAD API KEY (SECURE)
# -----------------------------
API_KEY = os.getenv("API_KEY")

if not API_KEY:
    raise RuntimeError("API_KEY not set in environment variables")

# -----------------------------
# APP CONFIG
# -----------------------------
app = FastAPI(
    title="AI Voice Authenticity Detection API",
    description="Detect whether a voice sample is AI-generated or Human-generated",
    version="1.0"
)

# -----------------------------
# REQUEST MODEL
# -----------------------------
class VoiceRequest(BaseModel):
    audio_base64: str
    language: str

# -----------------------------
# RESPONSE MODEL
# -----------------------------
class VoiceResponse(BaseModel):
    classification: str
    confidence: float
    explanation: str

# -----------------------------
# HOME PAGE
# -----------------------------
@app.get("/", response_class=HTMLResponse)
def home():
    with open("index.html", "r", encoding="utf-8") as f:
        return f.read()

# -----------------------------
# ENTROPY FUNCTION
# -----------------------------
def shannon_entropy(data: bytes) -> float:
    freq = {}
    for b in data:
        freq[b] = freq.get(b, 0) + 1

    entropy = 0.0
    length = len(data)
    for count in freq.values():
        p = count / length
        entropy -= p * math.log2(p)
    return entropy

# -----------------------------
# DETECTION ENDPOINT (LOCKED)
# -----------------------------
@app.post("/detect", response_model=VoiceResponse)
def detect_voice(
    request: VoiceRequest,
    x_api_key: str = Header(None)
):
    # ЁЯФР API KEY CHECK
    if x_api_key != API_KEY:
        raise HTTPException(
            status_code=401,
            detail="Unauthorized: Invalid API Key"
        )

    # Decode Base64
    try:
        audio_bytes = base64.b64decode(request.audio_base64)
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid Base64 audio")

    if len(audio_bytes) < 1000:
        raise HTTPException(status_code=400, detail="Audio too short for analysis")

    # Calculate entropy
    entropy = shannon_entropy(audio_bytes)

    # Classification logic
    if entropy > 7.2:
        classification = "AI-generated"
        confidence = round(min(0.95, (entropy - 6.5) / 2), 2)
    else:
        classification = "Human-generated"
        confidence = round(min(0.95, (7.2 - entropy) / 2), 2)

    # Language-based explanations
    explanations = {
        "tamil": {
            "AI-generated": "роЗроирпНрод родрооро┐ро┤рпН роХрпБро░ро▓ро┐ро▓рпН роЪрпЖропро▒рпНроХрпИ роирпБрогрпНрогро▒ро┐ро╡рпБроХрпНроХро╛рой роТро░рпЗ рооро╛родро┐ро░ро┐ропро╛рой роЪрпБро░рпБродро┐ рооро▒рпНро▒рпБроорпН роЗропроирпНродро┐ро░ рокрпЗроЪрпНроЪрпБ родройрпНроорпИроХро│рпН роХро╛рогрокрпНрокроЯрпБроХро┐ройрпНро▒рой.",
            "Human-generated": "роЗроирпНрод родрооро┐ро┤рпН роХрпБро░ро▓ро┐ро▓рпН роЗропро▓рпНрокро╛рой рооройро┐род рокрпЗроЪрпНроЪрпБ рооро╛ро▒рпНро▒роЩрпНроХро│рпН рооро▒рпНро▒рпБроорпН роЙрогро░рпНроЪрпНроЪро┐ ро╡рпЖро│ро┐рокрпНрокро╛роЯрпБроХро│рпН роХрогрпНроЯро▒ро┐ропрокрпНрокроЯрпНроЯрой."
        },
        "english": {
            "AI-generated": "The audio exhibits uniform pitch and synthesized speech patterns typical of AI-generated voices.",
            "Human-generated": "The audio shows natural variations in tone, rhythm, and emotion, indicating human speech."
        },
        "hindi": {
            "AI-generated": "рдЗрд╕ рд╣рд┐рдВрджреА рдСрдбрд┐рдпреЛ рдореЗрдВ рдХреГрддреНрд░рд┐рдо рдЖрд╡рд╛рдЬрд╝ рдХреЗ рд╕рдорд╛рди рд╕реНрдерд┐рд░ рд╕реНрд╡рд░ рдФрд░ рдпрд╛рдВрддреНрд░рд┐рдХ рдкреИрдЯрд░реНрди рдкрд╛рдП рдЧрдПред",
            "Human-generated": "рдЗрд╕ рд╣рд┐рдВрджреА рдСрдбрд┐рдпреЛ рдореЗрдВ рдкреНрд░рд╛рдХреГрддрд┐рдХ рдорд╛рдирд╡ рд╕реНрд╡рд░ рдкрд░рд┐рд╡рд░реНрддрди рдФрд░ рднрд╛рд╡рдирд╛рддреНрдордХ рдЕрднрд┐рд╡реНрдпрдХреНрддрд┐ рдкрд╛рдИ рдЧрдИред"
        },
        "malayalam": {
            "AI-generated": "р┤И р┤ор┤▓р┤пр┤╛р┤│р┤В р┤╢р┤мр╡Нр┤жр┤др╡Нр┤др┤┐р╡╜ р┤Хр╡Гр┤др╡Нр┤░р┤┐р┤о р┤╢р┤мр╡Нр┤жр┤др╡Нр┤др┤┐р┤ир╡Бр┤│р╡Нр┤│ р┤Пр┤Хр╡Ар┤Хр╡Гр┤д р┤╕р╡Нр┤╡р┤░ р┤ор┤╛р┤др╡Гр┤Хр┤Хр╡╛ р┤Хр┤╛р┤гр┤кр╡Нр┤кр╡Жр┤Яр╡Бр┤ир╡Нр┤ир╡Б.",
            "Human-generated": "р┤И р┤ор┤▓р┤пр┤╛р┤│р┤В р┤╢р┤мр╡Нр┤жр┤др╡Нр┤др┤┐р╡╜ р┤╕р╡Нр┤╡р┤╛р┤нр┤╛р┤╡р┤┐р┤Хр┤ор┤╛р┤п р┤ор┤ир╡Бр┤╖р╡Нр┤п р┤╢р┤мр╡Нр┤ж р┤╡р╡Нр┤пр┤др┤┐р┤пр┤╛р┤ир┤Щр╡Нр┤Щр╡╛ р┤Хр┤гр╡Нр┤Яр╡Жр┤др╡Нр┤др┤┐."
        },
        "telugu": {
            "AI-generated": "р░И р░др▒Жр░▓р▒Бр░Чр▒Б р░Жр░бр░┐р░пр▒Лр░▓р▒Л р░Хр▒Гр░др▒Нр░░р░┐р░о р░╕р▒Нр░╡р░░р░╛р░▓р░Хр▒Б р░╕р░Вр░мр░Вр░зр░┐р░Вр░Ър░┐р░и р░╕р▒Нр░ер░┐р░░р░ор▒Ир░и р░кр░┐р░Ър▒Н р░ир░ор▒Вр░ир░╛р░▓р▒Б р░Хр░ир░┐р░кр░┐р░╕р▒Нр░др▒Бр░ир▒Нр░ир░╛р░пр░┐.",
            "Human-generated": "р░И р░др▒Жр░▓р▒Бр░Чр▒Б р░Жр░бр░┐р░пр▒Лр░▓р▒Л р░╕р░╣р░Ьр░ор▒Ир░и р░ор░╛р░ир░╡ р░╕р▒Нр░╡р░░ р░ор░╛р░░р▒Нр░кр▒Бр░▓р▒Б р░Чр▒Бр░░р▒Нр░др░┐р░Вр░Ър░мр░бр▒Нр░бр░╛р░пр░┐."
        }
    }

    lang = request.language.lower()
    explanation = explanations.get(
        lang,
        {
            "AI-generated": "The audio exhibits synthesized speech characteristics.",
            "Human-generated": "The audio exhibits natural human speech patterns."
        }
    )[classification]

    return {
        "classification": classification,
        "confidence": confidence,
        "explanation": explanation
    }
